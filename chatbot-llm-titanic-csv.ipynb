{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17243,"sourceType":"datasetVersion","datasetId":12609}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Design a Chatbot","metadata":{}},{"cell_type":"code","source":"#!pip install pandas nltk flask transformers\nimport pandas as pd\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-02T06:07:21.191655Z","iopub.execute_input":"2024-10-02T06:07:21.192160Z","iopub.status.idle":"2024-10-02T06:07:21.657511Z","shell.execute_reply.started":"2024-10-02T06:07:21.192115Z","shell.execute_reply":"2024-10-02T06:07:21.656445Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Path to the Titanic dataset's CSV file on Kaggle\n# I assumes the training dataset as a main dataset and split it into train and test datasets later on in this notebook;\nfile_path = '/kaggle/input/titanic-machine-learning-from-disaster/train.csv'","metadata":{"execution":{"iopub.status.busy":"2024-10-02T06:07:52.311012Z","iopub.execute_input":"2024-10-02T06:07:52.311479Z","iopub.status.idle":"2024-10-02T06:07:52.317334Z","shell.execute_reply.started":"2024-10-02T06:07:52.311437Z","shell.execute_reply":"2024-10-02T06:07:52.315828Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Load the CSV into a pandas DataFrame\ntitanic_data = pd.read_csv(file_path)\n\n# Display the first few rows of the dataset\ntitanic_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-02T06:07:52.756983Z","iopub.execute_input":"2024-10-02T06:07:52.758084Z","iopub.status.idle":"2024-10-02T06:07:52.809437Z","shell.execute_reply.started":"2024-10-02T06:07:52.757958Z","shell.execute_reply":"2024-10-02T06:07:52.808002Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Check the data columns\nprint(titanic_data.columns)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T06:08:05.783943Z","iopub.execute_input":"2024-10-02T06:08:05.784500Z","iopub.status.idle":"2024-10-02T06:08:05.791823Z","shell.execute_reply.started":"2024-10-02T06:08:05.784449Z","shell.execute_reply":"2024-10-02T06:08:05.790267Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"# Basic User Input Understanding\n# Use NLP techniques to parse the user's query and match it to the table's columns.\n\nimport nltk\nnltk.download('punkt')\n\n# Define function to extract relevant words from user input\ndef preprocess_input(user_input):\n    words = nltk.word_tokenize(user_input.lower())  # Tokenize user input\n    return words\n\n# Basic column matching from the user input\ndef match_column(user_input):\n    columns = titanic_data.columns\n    words = preprocess_input(user_input)\n\n    for word in words:\n        if word in columns:\n            return word\n    return None\n","metadata":{"execution":{"iopub.status.busy":"2024-10-02T06:08:54.590935Z","iopub.execute_input":"2024-10-02T06:08:54.591477Z","iopub.status.idle":"2024-10-02T06:08:56.192021Z","shell.execute_reply.started":"2024-10-02T06:08:54.591418Z","shell.execute_reply":"2024-10-02T06:08:56.190614Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define Question and Answering Logic\ndef respond_to_query(user_input):\n    if 'survived' in preprocess_input(user_input):\n        survivors = titanic_data['Survived'].sum()\n        return f'There were {survivors} survivors.'\n    \n    # Find average age\n    if 'age' in preprocess_input(user_input) and 'average' in preprocess_input(user_input):\n        average_age = titanic_data['Age'].mean()\n        return f'The average age of passengers is {average_age:.2f}.'\n    \n    return \"Sorry, I didn't understand that.\"\n","metadata":{"execution":{"iopub.status.busy":"2024-10-02T06:29:22.707864Z","iopub.execute_input":"2024-10-02T06:29:22.708521Z","iopub.status.idle":"2024-10-02T06:29:22.717169Z","shell.execute_reply.started":"2024-10-02T06:29:22.708456Z","shell.execute_reply":"2024-10-02T06:29:22.715633Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Run the Chatbot\n# Chatbot loop\nprint(\"Hello, I am the Titanic chatbot. Ask me about the Titanic dataset.\")\nwhile True:\n    user_input = input(\"You: \")\n    if user_input.lower() == \"exit\":\n        print(\"Goodbye!\")\n        break\n    response = respond_to_query(user_input)\n    print(f\"Bot: {response}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-02T06:29:23.670679Z","iopub.execute_input":"2024-10-02T06:29:23.671150Z","iopub.status.idle":"2024-10-02T06:29:39.663626Z","shell.execute_reply.started":"2024-10-02T06:29:23.671105Z","shell.execute_reply":"2024-10-02T06:29:39.662185Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Hello, I am the Titanic chatbot. Ask me about the Titanic dataset.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  how many passenger ID?\n"},{"name":"stdout","text":"Bot: Sorry, I didn't understand that.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, I am the Titanic chatbot. Ask me about the Titanic dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoodbye!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"],"ename":"KeyboardInterrupt","evalue":"Interrupted by user","output_type":"error"}]},{"cell_type":"markdown","source":"# Handling More Complex Questions with NLP Models","metadata":{}},{"cell_type":"markdown","source":"Use a pre-trained language model from HuggingFace’s transformers library (like BERT) to parse more complex user questions. This will improve the bot’s understanding of natural language.","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\n# Load a pre-trained model for question answering\nqa_pipeline = pipeline(\"question-answering\")\n\ndef advanced_response(user_input):\n    # You can define a context string from the Titanic dataset.\n    # For instance, you can convert a subset of the dataset to text.\n    context = titanic_data.to_string()\n\n    # Use the pre-trained model to get an answer\n    result = qa_pipeline(question=user_input, context=context)\n    return result['answer']\n\n# Now the chatbot can use the advanced model\nprint(\"Ask more complex questions now!\")\nwhile True:\n    user_input = input(\"You: \")\n    if user_input.lower() == \"exit\":\n        print(\"Goodbye!\")\n        break\n    response = advanced_response(user_input)\n    print(f\"Bot: {response}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-02T06:29:45.638642Z","iopub.execute_input":"2024-10-02T06:29:45.639151Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Ask more complex questions now!\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  how many passengers are in the ship?\n"}]},{"cell_type":"code","source":"# Optionally Deploy the Chatbot with Flask (to create a web-based chatbot)\n\nfrom flask import Flask, request, jsonify\n\napp = Flask(__name__)\n\n@app.route(\"/chat\", methods=[\"POST\"])\ndef chat():\n    user_input = request.json.get(\"message\")\n    response = respond_to_query(user_input)  # Use simple or advanced response\n    return jsonify({\"response\": response})\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-02T06:25:11.379783Z","iopub.status.idle":"2024-10-02T06:25:11.380338Z","shell.execute_reply.started":"2024-10-02T06:25:11.380086Z","shell.execute_reply":"2024-10-02T06:25:11.380111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}