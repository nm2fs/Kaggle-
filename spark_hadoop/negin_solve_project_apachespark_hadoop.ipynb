{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8619fb2f-e864-47d9-8e18-37f429dd8805",
   "metadata": {},
   "source": [
    "# Use Case Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c00d12e-e5f1-4143-8bcc-71314c64dfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/06 17:39:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/10/06 17:39:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#Create a Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "spark = SparkSession\\\n",
    "            .builder\\\n",
    "            .appName(\"SparkWriterJob\")\\\n",
    "            .config(\"spark.sql.shuffle.partitions\", 2)\\\n",
    "            .config(\"spark.default.parallelism\", 2)\\\n",
    "            .master(\"local[2]\")\\\n",
    "            .getOrCreate()\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591594d5-1a69-4077-bb7b-02f92c7188a1",
   "metadata": {},
   "source": [
    "## Reading files into Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66aab5af-a6bb-4be5-adb4-9e54f14a669c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Student: string (nullable = true)\n",
      " |-- Subject: string (nullable = true)\n",
      " |-- ClassScore: double (nullable = true)\n",
      " |-- TestScore: double (nullable = true)\n",
      "\n",
      "+-------+---------+----------+---------+\n",
      "|Student|  Subject|ClassScore|TestScore|\n",
      "+-------+---------+----------+---------+\n",
      "|   Katy|     Math|      0.95|     2.37|\n",
      "|   Katy|Chemistry|       0.5|     1.18|\n",
      "|   Katy|  Physics|      0.48|     1.37|\n",
      "|   Katy|  Biology|      0.75|     2.79|\n",
      "|   Mike|     Math|      0.45|     1.79|\n",
      "+-------+---------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read the raw CSV file int a Spark DataFrame\n",
    "#    Use inferSchema to infer the schema automatically from the CSV file\n",
    "\n",
    "student_scores_data = spark\\\n",
    "                .read\\\n",
    "                .option(\"inferSchema\", \"true\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .csv(\"datasets/student_scores.csv\")\n",
    "\n",
    "# Print the schema for verification\n",
    "student_scores_data.printSchema();\n",
    "\n",
    "#Print the first 5 records for verification\n",
    "student_scores_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28faaa99-2cc5-4504-bb57-d65cf67cac0d",
   "metadata": {},
   "source": [
    "## Writing to HDFS as a parquet file, use GZIP as a compression codec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8db1c152-73ff-45cc-a397-fc4abc98ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_scores_data.write\\\n",
    "            .option(\"compression\", \"gzip\")\\\n",
    "            .parquet(path=\"dummy_student_hdfs/raw_parquet\",\n",
    "                    mode=\"overwrite\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be0c53f-5fe7-4649-9bd3-43c4d04081f1",
   "metadata": {},
   "source": [
    "## Write to HDFS with partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5a49487-326f-4aad-9cc6-8815c75183ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (2479332955.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    .partitionBy(\"Student\")\\             # I choose student column to be partitioned upon\u001b[0m\n\u001b[0m                                                                                         \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "student_scores_data.write\\\n",
    "            .option(\"compression\", \"gzip\")\\\n",
    "            .partitionBy(\"Student\")\\             # I choose student column to be partitioned upon\n",
    "            .parquet(path=\"dummy_student_hdfs/partitioned_parquet\",\n",
    "                    mode=\"overwrite\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b4f250d-cc8f-46ef-a2be-e59411d9afd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------+---------+\n",
      "|Student|  Subject|ClassScore|TestScore|\n",
      "+-------+---------+----------+---------+\n",
      "|   John|     Math|      0.27|      1.2|\n",
      "|   John|Chemistry|      0.44|     2.76|\n",
      "|   John|  Physics|      0.82|      2.8|\n",
      "|   John|  Biology|      0.41|     2.71|\n",
      "+-------+---------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "#Use a partition attribute for filtering\n",
    "john_df = student_scores_data.where(col(\"Student\") == 'John')\n",
    "john_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb05c088-f1c8-4ed9-b5fd-6a8a50362a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Student: string, Subject: string, ClassScore: double, TestScore: double, totalscore: double]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "john_df_physics = john_df.filter(col(\"Subject\") == 'Physics').withColumn(\"totalscore\", col('ClassScore') + col ('TestScore'))\n",
    "\n",
    "john_df_physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c92f30e-d921-46d4-ac45-b42bbe939cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+---------+------------------+\n",
      "|Student|Subject|ClassScore|TestScore|        totalscore|\n",
      "+-------+-------+----------+---------+------------------+\n",
      "|   John|Physics|      0.82|      2.8|3.6199999999999997|\n",
      "+-------+-------+----------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print total score for each student in Physics\n",
    "john_df_physics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7e0ec00-79ab-4cbe-9410-d53e9565e14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------+---------+\n",
      "|Student|  Subject|ClassScore|TestScore|\n",
      "+-------+---------+----------+---------+\n",
      "|   Katy|     Math|      0.95|     2.37|\n",
      "|   Katy|Chemistry|       0.5|     1.18|\n",
      "|   Katy|  Physics|      0.48|     1.37|\n",
      "|   Katy|  Biology|      0.75|     2.79|\n",
      "|   Mike|     Math|      0.45|     1.79|\n",
      "|   Mike|Chemistry|      0.39|     1.21|\n",
      "|   Mike|  Physics|      0.34|     2.72|\n",
      "|   Mike|  Biology|      0.57|     2.35|\n",
      "|    Bob|     Math|      0.36|     2.37|\n",
      "|    Bob|Chemistry|      0.86|     1.26|\n",
      "|    Bob|  Physics|      0.93|     2.89|\n",
      "|    Bob|  Biology|      0.52|     2.87|\n",
      "|   Lisa|     Math|      0.33|     2.86|\n",
      "|   Lisa|Chemistry|      0.64|     1.05|\n",
      "|   Lisa|  Physics|      0.42|     2.34|\n",
      "|   Lisa|  Biology|      0.39|     1.53|\n",
      "|   John|     Math|      0.27|      1.2|\n",
      "|   John|Chemistry|      0.44|     2.76|\n",
      "|   John|  Physics|      0.82|      2.8|\n",
      "|   John|  Biology|      0.41|     2.71|\n",
      "+-------+---------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_scores_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53748b71-2831-4139-96ff-1a447b64f9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+---------+\n",
      "|Student|Subject|ClassScore|TestScore|\n",
      "+-------+-------+----------+---------+\n",
      "|   Katy|Physics|      0.48|     1.37|\n",
      "|   Mike|Physics|      0.34|     2.72|\n",
      "|    Bob|Physics|      0.93|     2.89|\n",
      "|   Lisa|Physics|      0.42|     2.34|\n",
      "|   John|Physics|      0.82|      2.8|\n",
      "+-------+-------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_scores_data_physics = student_scores_data.filter(col('Subject') == 'Physics')\n",
    "student_scores_data_physics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8b44b1f-66e4-458d-a96b-3cee5a6937b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+---------+------------------+\n",
      "|Student|Subject|ClassScore|TestScore|        totalscore|\n",
      "+-------+-------+----------+---------+------------------+\n",
      "|   Katy|Physics|      0.48|     1.37|              1.85|\n",
      "|   Mike|Physics|      0.34|     2.72|              3.06|\n",
      "|    Bob|Physics|      0.93|     2.89|3.8200000000000003|\n",
      "|   Lisa|Physics|      0.42|     2.34|              2.76|\n",
      "|   John|Physics|      0.82|      2.8|3.6199999999999997|\n",
      "+-------+-------+----------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student_scores_data_physics = student_scores_data_physics.withColumn(\"totalscore\", col('ClassScore') + col ('TestScore'))\n",
    "student_scores_data_physics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10ec78cb-0200-427a-aadd-9efe864e7a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------+---------+------------------+\n",
      "|Student|  Subject|ClassScore|TestScore|        totalscore|\n",
      "+-------+---------+----------+---------+------------------+\n",
      "|   Katy|     Math|      0.95|     2.37|3.3200000000000003|\n",
      "|   Katy|Chemistry|       0.5|     1.18|              1.68|\n",
      "|   Katy|  Physics|      0.48|     1.37|              1.85|\n",
      "|   Katy|  Biology|      0.75|     2.79|              3.54|\n",
      "|   Mike|     Math|      0.45|     1.79|              2.24|\n",
      "|   Mike|Chemistry|      0.39|     1.21|               1.6|\n",
      "|   Mike|  Physics|      0.34|     2.72|              3.06|\n",
      "|   Mike|  Biology|      0.57|     2.35|              2.92|\n",
      "|    Bob|     Math|      0.36|     2.37|              2.73|\n",
      "|    Bob|Chemistry|      0.86|     1.26|              2.12|\n",
      "|    Bob|  Physics|      0.93|     2.89|3.8200000000000003|\n",
      "|    Bob|  Biology|      0.52|     2.87|              3.39|\n",
      "|   Lisa|     Math|      0.33|     2.86|              3.19|\n",
      "|   Lisa|Chemistry|      0.64|     1.05|              1.69|\n",
      "|   Lisa|  Physics|      0.42|     2.34|              2.76|\n",
      "|   Lisa|  Biology|      0.39|     1.53|              1.92|\n",
      "|   John|     Math|      0.27|      1.2|              1.47|\n",
      "|   John|Chemistry|      0.44|     2.76|3.1999999999999997|\n",
      "|   John|  Physics|      0.82|      2.8|3.6199999999999997|\n",
      "|   John|  Biology|      0.41|     2.71|              3.12|\n",
      "+-------+---------+----------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute avg total score for each student across all subjects\n",
    "student_scores_data = student_scores_data.withColumn(\"totalscore\", col('ClassScore') + col ('TestScore'))\n",
    "student_scores_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87189229-86de-4a95-a9f8-97078533b20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|Student|   avg_total_score|\n",
      "+-------+------------------+\n",
      "|   Mike|             2.455|\n",
      "|   Lisa|2.3899999999999997|\n",
      "|   John|            2.8525|\n",
      "|   Katy|            2.5975|\n",
      "|    Bob|             3.015|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, avg\n",
    "# agg: This function applies one or more aggregate functions to each group created by groupBy. \n",
    "# Aggregates include functions like sum(), count(), avg(), etc.\n",
    "# alias(\"avg_total_score\"): This renames the result of the average calculation to avg_total_score. Without this, the result would have the default name avg(totalscore), which can be less readable. \n",
    "# Using alias makes the column name more meaningful.\n",
    "avg_total_scores = student_scores_data.groupby('Student').agg(avg('totalscore').alias(\"avg_total_score\")) \n",
    "avg_total_scores.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9c8f313-9ce9-4f55-a472-983294ab2dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|  Subject|   max(totalscore)|\n",
      "+---------+------------------+\n",
      "|  Biology|              3.54|\n",
      "|     Math|3.3200000000000003|\n",
      "|Chemistry|3.1999999999999997|\n",
      "|  Physics|3.8200000000000003|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the student with highest score for each subject\n",
    "\n",
    "high_score = student_scores_data.groupby('Subject').max('totalscore')\n",
    "high_score.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c108721-64a4-484e-9c53-a0a4c39adea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|  Subject|    max_totalscore|\n",
      "+---------+------------------+\n",
      "|  Biology|              3.54|\n",
      "|     Math|3.3200000000000003|\n",
      "|Chemistry|3.1999999999999997|\n",
      "|  Physics|3.8200000000000003|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Compute the max total score for each subject\n",
    "high_score = student_scores_data.groupby('Subject').agg({\"totalscore\": \"max\"}).withColumnRenamed(\"max(totalscore)\", \"max_totalscore\")\n",
    "high_score.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88afb457-607c-4533-b790-559156dcc449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------------+\n",
      "|Student|  Subject|        totalscore|\n",
      "+-------+---------+------------------+\n",
      "|   Katy|     Math|3.3200000000000003|\n",
      "|   Katy|  Biology|              3.54|\n",
      "|    Bob|  Physics|3.8200000000000003|\n",
      "|   John|Chemistry|3.1999999999999997|\n",
      "+-------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Join with the original DataFrame to get the student name\n",
    "high_score_with_student = student_scores_data.alias(\"original\").join(\n",
    "    high_score.alias(\"max_scores\"),\n",
    "    (col(\"original.Subject\") == col(\"max_scores.Subject\")) & (col(\"original.totalscore\") == col(\"max_scores.max_totalscore\")),\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "high_score_with_student.select(\"original.Student\", \"original.Subject\", \"original.totalscore\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d37b27-9017-45c6-86b4-9b5e00171146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
